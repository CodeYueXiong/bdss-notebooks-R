{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In an ideal world, we will have all of the data we want with all of the desirable properties (no missing values, no errors, standard formats, and so on). \n",
    "However, that is hardly ever true - and we have to work with using our datasets to answer questions of interest as intelligently as possible. \n",
    "\n",
    "In this notebook, we will explore our datasets to answer some questions of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "This notebook will give you the opportunity to spend some hands-on time with the data. \n",
    "\n",
    "This notebook will take you around the different ways you can analyze your data. This involves looking at basic metrics in the larger dataset, taking a random sample, creating derived variables, making sense of the missing values, and so on. \n",
    "\n",
    "This will be done using both SQL and `pandas` in Python. The `sqlite3` Python package will give you the opportunity to interact with the database using SQL to pull data into Python. Some additional manipulations will be handled by Pandas in Python (by converting your datasets into dataframes).\n",
    "\n",
    "This notebook will provide an introduction and examples for: \n",
    "\n",
    "- How to create new tables from the larger tables in database (sometimes called the \"analytical frame\")\n",
    "- How to explore different variables of interest\n",
    "- How to explore aggregate metrics\n",
    "- How to handle missing values\n",
    "- How to join newly created tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "We will be using the `sqlite3` Python package to access tables in our database - SQLite3. \n",
    "\n",
    "To read the results of our queries, we will be using the `pandas` Python package, which has the ability to read tabular data from SQL queries into a pandas DataFrame object. Within `pandas`, we will use various commands to:\n",
    "\n",
    "- Create statistical summaries\n",
    "- Create subsets of the data\n",
    "\n",
    "Within SQL, we will use various queries to:\n",
    "\n",
    "- select data subsets\n",
    "- Sum over groups\n",
    "- create new tables\n",
    "- Count distinct values of desired variables\n",
    "- Order data by chosen variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "\n",
    "In Python, we `import` packages. The `import` command allows us to use libraries created by others in our own work by \"importing\" them. You can think of importing a library as opening up a toolbox and pulling out a specific tool. Among the most famous Python packages:\n",
    "- `numpy` is short for \"numerical Python\". `numpy` is a lynchpin in Python's scientific computing stack. Its strengths include a powerful *N*-dimensional array object, and a large suite of functions for doing numerical computing. \n",
    "- `pandas` is a library in Python for data analysis that uses the DataFrame object (modeled after R DataFrames, for those familiar with that language) which is similiar to a spreedsheet but allows you to do your analysis programaticaly rather than the point-and-click of Excel. It is a lynchpin of the PyData stack and is built on top of `numpy`.  \n",
    "- `sqlite3` is a library that helps us connect to an sqlite3 database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "\n",
    "# database interaction imports\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When in doubt, use shift + tab to read the documentation of a method.__\n",
    "\n",
    "__The `help()` function provides information on what you can do with a function.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example\n",
    "help(sqlite3.connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We can execute SQL queries using Python to get the best of both worlds. For example, Python - and pandas in particular - make it much easier to calculate descriptive statistics of the data. Additionally, as we will see in the Data Visualization exercises, it is relatively easy to create data visualizations using Python. \n",
    "\n",
    "Pandas provides many ways to load data. It allows the user to read the data from a local csv or excel file, pull the data from a relational database, or read directly from a URL (when you have internet access). Since we are working with an SQLite3 database, we will demonstrate how to use pandas to read data from a relational database. For examples to read data from a CSV file, refert to the pandas documentation [Getting Data In/Out](pandas.pydata.org/pandas-docs/stable/10min.html#getting-data-in-out).\n",
    "\n",
    "The function to run a SQL query and pull the data into a pandas dataframe (more to come) is `pd.read_sql()`. Just like doing a SQL query from pgAdmin, this function will ask for some information about the database, and what query you would like to run. Let's walk through the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Connection to the Database\n",
    "\n",
    "The first parameter is the connection to the database. To create a connection we will use the SQLAlchemy package and tell it which database we want to connect to, just like in pgAdmin. Additional details on creating a connection to the database are provided in the [Databases](02_1_Databases.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter 1: Connection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, \n",
    "# we need to pass the name of the database \n",
    "\n",
    "DB = 'testing/ncdoc.db'\n",
    "\n",
    "conn = sqlite3.connect(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate Data Query\n",
    "\n",
    "Depending on what data we are interested in, we can use different queries to pull different data. In this example, we will pull all the content of the offenders data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a query as a `string` object in Python__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM inmate\n",
    "LIMIT 20;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- the three quotation marks surrounding the query body is called multi-line string. It is quite handy for writing SQL queries because the new line character will be considered part of the string, instead of breaking the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have defined a variable `query`, we can call it in the code\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the `LIMIT` provides one simple way to get a \"sample\" of data; however, using `LIMIT` does **not provide a _random_** sample. You may get different samples of data than others using just the `LIMIT` clause, but it is just based on what is fastest for the database to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Data from the Database\n",
    "\n",
    "Now that we have the two parameters (database connection and query), we can pass them to the `pd.read_sql()` function, and obtain the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we pass the query and the connection to the pd.read_sql() function and assign the variable `wage` \n",
    "# to the dataframe returned by the function\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Using Python and SQL\n",
    "\n",
    "__What are the characteristics of inmates/offenders in North Carolina?__\n",
    "\n",
    "Before we go any further, let's take a look at some of the data that we're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__North Carolina Department of Corrections Data__:\n",
    "- `inmate`: Characteristics about each inmate.\n",
    "- `offender`: Characteristics about each offender.\n",
    "- `sentences`: Transactional-level data about sentences.\n",
    "\n",
    "Note that each row in the both the `inmate` and `offender` tables represents one person. However, the same person can have multiple sentences. Information about each person is included in the `inmate` and `offender` tables, separate from the actual sentences, because we don't want to have to repeat the information about about each person multiple times, as would be the case if we had just one large table with all of the relevant information. \n",
    "\n",
    "Let's bring in a subset of the offender data to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM offender\n",
    "limit 100;\n",
    "'''\n",
    "offender = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `head()` method to look at the top few rows of the offender data. As you can see, we have lots of information about the person, such as date of birth, gender, height, weight, hair color and so on. Let's see all of the types of variables that we have in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offender.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Missing Values\n",
    "\n",
    "We might be concerned about missing values in our data. Let's take a look at some inmate data to show an example of how we might find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM inmate\n",
    "limit 10000;\n",
    "'''\n",
    "inmate = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some values seem to be missing. We don't really care as much about a missing middle initial, but we might be concerned that the inmate's race might be missing. Let's see if we can identify if there are any missing in that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "inmate['INMATE_RACE_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's one missing value out of the 10,000 sample that we took from the inmate table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some offenders are missing the NC County where they were born. Let's see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offender['NC_COUNTY_WHERE_OFFENDER_BORN'].value_counts() # some are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just for the sample. What about for the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating read SQL\n",
    "query = '''\n",
    "SELECT count(distinct OFFENDER_NC_DOC_ID_NUMBER)\n",
    "FROM offender\n",
    "WHERE NC_COUNTY_WHERE_OFFENDER_BORN IS \"\"\n",
    "'''\n",
    "# read the query into a DataFrame\n",
    "missing_county = pd.read_sql(query, conn)\n",
    "# print the resulting DataFrame\n",
    "missing_county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, we can also find he total number of people. We count both the distinct inmate DOC numbers as well as the number of rows just to make sure that we don't have any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating read SQL\n",
    "query = '''\n",
    "SELECT count(distinct INMATE_DOC_NUMBER), count(*)\n",
    "FROM inmate\n",
    "'''\n",
    "# read the query into a DataFrame\n",
    "unique_offender = pd.read_sql(query, conn)\n",
    "# print the resulting DataFrame\n",
    "unique_offender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Variables\n",
    "\n",
    "SQL and Python have specific ways of dealing with date variables so that we can use them in intuitive ways. For example, we can extract out the year from a date and use that separately from the date itself. For example, suppose we want to get everyone who was an inmate during the 1980s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at every inmate in the 1980s\n",
    "\n",
    "# set the SQL query\n",
    "query =\"\"\"\n",
    "SELECT *, CAST(strftime(\"%Y\",ACTUAL_SENTENCE_END_DATE) as integer) as release_year\n",
    "FROM sentences\n",
    "WHERE release_year >= 1980 AND release_year < 1990\n",
    "\"\"\"\n",
    "\n",
    "# print the query for reference\n",
    "print(query)\n",
    "\n",
    "# read the query \n",
    "\n",
    "in80 = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in80.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "In this section, let's start looking at aggregate statistics on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"\n",
    "SELECT *\n",
    "FROM sentences\n",
    "\"\"\"\n",
    "# print results\n",
    "sentences = pd.read_sql(qry,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `INMATE_SENTENCE_COMPONENT` column. This shows that the there might be multiple rows for multi-part sentences, and the sentence end date is the same for each of these separate sentences. Since we want to make sure they are treated as one whole sentence, we can simply take the first component of each sentence (since we are only interested in the sentence end date for right now). We'll make sure to do this for all future queries.\n",
    "\n",
    "Let's look at how many sentences ended in the 1980s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we're using a slightly different way of determining who ended their sentence \n",
    "qry = \"\"\"\n",
    "SELECT count(*)\n",
    "FROM sentences\n",
    "WHERE ACTUAL_SENTENCE_END_DATE >= '1980-01-01' AND ACTUAL_SENTENCE_END_DATE < '1990-01-01'\n",
    "AND INMATE_SENTENCE_COMPONENT == '001'\n",
    "\"\"\"\n",
    "# print results\n",
    "print(pd.read_sql(qry, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get this in a data frame to explore further\n",
    "\n",
    "qry = \"\"\"\n",
    "SELECT *\n",
    "FROM sentences\n",
    "WHERE ACTUAL_SENTENCE_END_DATE >= '1980-01-01' AND ACTUAL_SENTENCE_END_DATE < '1990-01-01'\n",
    "AND INMATE_SENTENCE_COMPONENT == '001'\n",
    "\"\"\"\n",
    "# print results\n",
    "df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get descriptive stats from the DataFrame:\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many records from our inmate data matches the offender data\n",
    "\n",
    "qry = \"\"\"\n",
    "SELECT *\n",
    "FROM offender\n",
    "JOIN inmate\n",
    "ON offender.OFFENDER_NC_DOC_ID_NUMBER = inmate.INMATE_DOC_NUMBER\n",
    "\"\"\"\n",
    "inoff = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the distribution of height in our sample?\n",
    "height = inoff['OFFENDER_HEIGHT_(IN_INCHES)'].astype(float)\n",
    "inoff['OFFENDER_HEIGHT_(IN_INCHES)'] = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles of height\n",
    "inoff['OFFENDER_HEIGHT_(IN_INCHES)'].describe(percentiles=[0.1,0.25,0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Percentiles of height by gender\n",
    "inoff.groupby('INMATE_GENDER_CODE')['OFFENDER_HEIGHT_(IN_INCHES)'].describe(percentiles=[0.1,0.25,0.5, 0.75, 0.9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "566px",
    "left": "0px",
    "right": "954px",
    "top": "110px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
